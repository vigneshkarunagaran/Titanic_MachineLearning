{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/titanic/gender_submission.csv\n",
      "/kaggle/input/titanic/test.csv\n",
      "/kaggle/input/titanic/train.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/titanic/train.csv')\n",
    "X_test = pd.read_csv('/kaggle/input/titanic/test.csv')\n",
    "submission_data = pd.read_csv('/kaggle/input/titanic/gender_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n",
      "__________________________________________________\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(train_data.info())\n",
    "print('_'*50)\n",
    "print(X_test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "__________________________________________________\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data.isna().sum())\n",
    "print('_'*50)\n",
    "print(X_test.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Train Dataset\n",
    "\n",
    "Though Cabin column has so many NaN, from one of the kaggle notebooks availabe i found that it plays a major role in survival (i.e. location of their cabin plays a major role). And most of the NaN data are associated with class 3 passangers which results in correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Age'].fillna(train_data['Age'].mean(), inplace = True)\n",
    "train_data['Cabin'].fillna('N0', inplace = True)\n",
    "train_data['Deck'] = train_data[\"Cabin\"].str.slice(0,1)\n",
    "train_data['Embarked'].fillna('S', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_dummy = pd.get_dummies(train_data['Sex'], drop_first = True)\n",
    "class_dummy = pd.get_dummies(train_data['Pclass'], drop_first = True)\n",
    "embarked_dummy = pd.get_dummies(train_data['Embarked'], drop_first = True)\n",
    "deck_dummy = pd.get_dummies(train_data['Deck'], drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(['Pclass','Name','Cabin','Deck', 'Sex', 'Ticket', 'Embarked'], axis = 1, inplace = True)\n",
    "train_data = pd.concat([train_data, sex_dummy, class_dummy,embarked_dummy,deck_dummy], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['Age'].fillna(X_test['Age'].mean(), inplace = True)\n",
    "X_test['Cabin'].fillna('N0', inplace = True)\n",
    "X_test['Deck'] = X_test[\"Cabin\"].str.slice(0,1)\n",
    "X_test['Fare'].fillna(X_test['Fare'].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_dummy = pd.get_dummies(X_test['Sex'], drop_first = True)\n",
    "class_dummy = pd.get_dummies(X_test['Pclass'], drop_first = True)\n",
    "embarked_dummy = pd.get_dummies(X_test['Embarked'], drop_first = True)\n",
    "deck_dummy = pd.get_dummies(X_test['Deck'], drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.drop(['Pclass','Name','Cabin','Deck', 'Sex', 'Ticket', 'Embarked'], axis = 1, inplace = True)\n",
    "X_test = pd.concat([X_test, sex_dummy, class_dummy,embarked_dummy,deck_dummy], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Column 'T' with zeros since Test dataset does't contain 'T' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['T'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId',    'Survived',         'Age',       'SibSp',\n",
      "             'Parch',        'Fare',        'male',             2,\n",
      "                   3,           'Q',           'S',           'B',\n",
      "                 'C',           'D',           'E',           'F',\n",
      "                 'G',           'N',           'T'],\n",
      "      dtype='object')\n",
      "__________________________________________________\n",
      "Index(['PassengerId',         'Age',       'SibSp',       'Parch',\n",
      "              'Fare',        'male',             2,             3,\n",
      "                 'Q',           'S',           'B',           'C',\n",
      "                 'D',           'E',           'F',           'G',\n",
      "                 'N',           'T'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train_data.columns)\n",
    "print('_'*50)\n",
    "print(X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependent and Independent Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_data['Survived']\n",
    "train_data = train_data.drop('Survived' , axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train - Validation data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_data,y, test_size = 0.1, random_state = 0                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 801 entries, 815 to 684\n",
      "Data columns (total 18 columns):\n",
      "PassengerId    801 non-null int64\n",
      "Age            801 non-null float64\n",
      "SibSp          801 non-null int64\n",
      "Parch          801 non-null int64\n",
      "Fare           801 non-null float64\n",
      "male           801 non-null uint8\n",
      "2              801 non-null uint8\n",
      "3              801 non-null uint8\n",
      "Q              801 non-null uint8\n",
      "S              801 non-null uint8\n",
      "B              801 non-null uint8\n",
      "C              801 non-null uint8\n",
      "D              801 non-null uint8\n",
      "E              801 non-null uint8\n",
      "F              801 non-null uint8\n",
      "G              801 non-null uint8\n",
      "N              801 non-null uint8\n",
      "T              801 non-null uint8\n",
      "dtypes: float64(2), int64(3), uint8(13)\n",
      "memory usage: 47.7 KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_val, y_pred)\n",
    "print((cm[0,0]+cm[1,1])/cm.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_submit = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame()\n",
    "results_df['PassengerId'] = X_test['PassengerId']\n",
    "results_df[\"Survived\"] = y_submit\n",
    "results_df.to_csv(\"Predictions\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
